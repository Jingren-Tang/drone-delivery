{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb37443",
   "metadata": {},
   "source": [
    "# Linear regression model for car following\n",
    "\n",
    "This notebook was written by Evangelos Paschalidis (evangelos.paschalidis@epfl.ch) for the Decision-aid methodologies in transportation course at EPFL (http://edu.epfl.ch/coursebook/en/decision-aid-methodologies-in-transportation-CIVIL-557). \n",
    "\n",
    "Please contact before distributing or reusing the material below.\n",
    "\n",
    "## Context: car following\n",
    "\n",
    "We have a database of acceleration behaviour in car-following situations.\n",
    "\n",
    "**Task: Specify and estimate a linear model using as explanatory variables:**\n",
    "\n",
    "**- Speed**\n",
    "\n",
    "**- Relative speed (Lead speed and speed differenece)**\n",
    "\n",
    "**- Distance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ad16e",
   "metadata": {},
   "source": [
    "## Load packages\n",
    "\n",
    "Before we estimate the model let's load some packages that we are going to need. When importing a package, it is common to rename it using an abbreviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a2baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data frame processing\n",
    "import numpy as np # for some statistical procedures\n",
    "from scipy.optimize import minimize # optimisation routine for parameter estimation\n",
    "from scipy.stats import norm # normal distribution density function\n",
    "import numdifftools as nd # we use this to calculate t-ratios and p-values\n",
    "import csv # we need this to store our parameters as csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431fb5b4",
   "metadata": {},
   "source": [
    "### Let's give a name to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6900880",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'car_following_model' # Name we want to give to our model (this is used when saving the output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621626a4",
   "metadata": {},
   "source": [
    "### Panel structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3422be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = 0 # switch to 1 if data is panel (any other value if not panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e3fb6",
   "metadata": {},
   "source": [
    "### Define if we use mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efc28d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixing = 0 # switch to 1 if we apply mixing (any other value if no mixing applied)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e12a2a2",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Now it is time to load the data. We can do that using the piece of code below.\n",
    "\n",
    "**Important!** Make sure the data is in the same folder with the notebook file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be01c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to load the data\n",
    "data = pd.read_table('I80_data0.txt')\n",
    "\n",
    "# Number of observations (we need this to caclulate goodness-of-fit indices)\n",
    "Nobs = data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e03b17",
   "metadata": {},
   "source": [
    "## Print the data\n",
    "\n",
    "Let's quickly print the data. Simply type *data* in the field below\n",
    "\n",
    "(If we had opened our data set with a different name e.g. *database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "176b4f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Position</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Type</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Lane</th>\n",
       "      <th>Leader</th>\n",
       "      <th>...</th>\n",
       "      <th>lead04</th>\n",
       "      <th>lane01</th>\n",
       "      <th>lane02</th>\n",
       "      <th>lane03</th>\n",
       "      <th>lane04</th>\n",
       "      <th>tasks</th>\n",
       "      <th>task_index</th>\n",
       "      <th>timelag</th>\n",
       "      <th>dd</th>\n",
       "      <th>idd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>83.033604</td>\n",
       "      <td>4.084802</td>\n",
       "      <td>-9999.99</td>\n",
       "      <td>2</td>\n",
       "      <td>6.847780</td>\n",
       "      <td>-2.266411</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>87.759061</td>\n",
       "      <td>4.084802</td>\n",
       "      <td>-9999.99</td>\n",
       "      <td>2</td>\n",
       "      <td>3.295830</td>\n",
       "      <td>-1.349331</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>90.960723</td>\n",
       "      <td>4.084802</td>\n",
       "      <td>-9999.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2.820909</td>\n",
       "      <td>-2.040139</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>92.047244</td>\n",
       "      <td>4.084802</td>\n",
       "      <td>-9999.99</td>\n",
       "      <td>2</td>\n",
       "      <td>0.276981</td>\n",
       "      <td>0.345661</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>92.601824</td>\n",
       "      <td>4.084802</td>\n",
       "      <td>-9999.99</td>\n",
       "      <td>2</td>\n",
       "      <td>0.634731</td>\n",
       "      <td>0.365870</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18421</th>\n",
       "      <td>3340</td>\n",
       "      <td>110</td>\n",
       "      <td>397.345232</td>\n",
       "      <td>4.359100</td>\n",
       "      <td>-9999.99</td>\n",
       "      <td>2</td>\n",
       "      <td>10.053292</td>\n",
       "      <td>-0.356570</td>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>51</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>3340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18422</th>\n",
       "      <td>3340</td>\n",
       "      <td>111</td>\n",
       "      <td>406.291822</td>\n",
       "      <td>4.359100</td>\n",
       "      <td>-9999.99</td>\n",
       "      <td>2</td>\n",
       "      <td>8.161121</td>\n",
       "      <td>-0.587411</td>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>3340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18423</th>\n",
       "      <td>3340</td>\n",
       "      <td>112</td>\n",
       "      <td>414.387694</td>\n",
       "      <td>4.359100</td>\n",
       "      <td>-9999.99</td>\n",
       "      <td>2</td>\n",
       "      <td>8.106680</td>\n",
       "      <td>0.110621</td>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>53</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>3340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18424</th>\n",
       "      <td>3340</td>\n",
       "      <td>113</td>\n",
       "      <td>422.633135</td>\n",
       "      <td>4.359100</td>\n",
       "      <td>-9999.99</td>\n",
       "      <td>2</td>\n",
       "      <td>8.298771</td>\n",
       "      <td>-0.182639</td>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>3340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18425</th>\n",
       "      <td>3340</td>\n",
       "      <td>114</td>\n",
       "      <td>430.471933</td>\n",
       "      <td>4.359100</td>\n",
       "      <td>-9999.99</td>\n",
       "      <td>2</td>\n",
       "      <td>7.373280</td>\n",
       "      <td>-0.246330</td>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>3340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18426 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Time    Position    Length    Width  Type      Speed  \\\n",
       "0         4    26   83.033604  4.084802 -9999.99     2   6.847780   \n",
       "1         4    27   87.759061  4.084802 -9999.99     2   3.295830   \n",
       "2         4    28   90.960723  4.084802 -9999.99     2   2.820909   \n",
       "3         4    29   92.047244  4.084802 -9999.99     2   0.276981   \n",
       "4         4    30   92.601824  4.084802 -9999.99     2   0.634731   \n",
       "...     ...   ...         ...       ...      ...   ...        ...   \n",
       "18421  3340   110  397.345232  4.359100 -9999.99     2  10.053292   \n",
       "18422  3340   111  406.291822  4.359100 -9999.99     2   8.161121   \n",
       "18423  3340   112  414.387694  4.359100 -9999.99     2   8.106680   \n",
       "18424  3340   113  422.633135  4.359100 -9999.99     2   8.298771   \n",
       "18425  3340   114  430.471933  4.359100 -9999.99     2   7.373280   \n",
       "\n",
       "       Acceleration  Lane  Leader  ...  lead04  lane01  lane02  lane03  \\\n",
       "0         -2.266411     5      21  ...       1       1       1       1   \n",
       "1         -1.349331     5      21  ...       1       1       1       1   \n",
       "2         -2.040139     5      21  ...       1       1       1       1   \n",
       "3          0.345661     5      21  ...       1       1       1       1   \n",
       "4          0.365870     5      21  ...       1       1       1       1   \n",
       "...             ...   ...     ...  ...     ...     ...     ...     ...   \n",
       "18421     -0.356570     2     117  ...       1       1       1       1   \n",
       "18422     -0.587411     2     117  ...       1       1       1       1   \n",
       "18423      0.110621     2     117  ...       1       1       1       1   \n",
       "18424     -0.182639     2     117  ...       1       1       1       1   \n",
       "18425     -0.246330     2     117  ...       1       1       1       1   \n",
       "\n",
       "       lane04  tasks  task_index  timelag  dd   idd  \n",
       "0           1     28           5       25   1     4  \n",
       "1           1     28           6       26   1     4  \n",
       "2           1     28           7       27   1     4  \n",
       "3           1     28           8       28   1     4  \n",
       "4           1     28           9       29   1     4  \n",
       "...       ...    ...         ...      ...  ..   ...  \n",
       "18421       1     55          51      109   1  3340  \n",
       "18422       1     55          52      110   1  3340  \n",
       "18423       1     55          53      111   1  3340  \n",
       "18424       1     55          54      112   1  3340  \n",
       "18425       1     55          55      113   1  3340  \n",
       "\n",
       "[18426 rows x 81 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type \"data\" in this field (without the quotation) and run the cell (Shift + return)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcff136",
   "metadata": {},
   "source": [
    "## Print the variable names (columns)\n",
    "\n",
    "We can also print the variable names only using the piece of code below\n",
    "\n",
    "* This is useful during model specification to easily access the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e385d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Time', 'Position', 'Length', 'Width', 'Type', 'Speed',\n",
      "       'Acceleration', 'Lane', 'Leader', 'Follower', 'Space_headway',\n",
      "       'Time_headway', 'Acceleration_lead', 'Speed_lead', 'Position_lead',\n",
      "       'Density', 'distanceToEnd', 'lane_change', 'lead_change', 'lag_leader0',\n",
      "       'lag_leader1', 'lag_leader2', 'lag_leader3', 'lag_leader4', 'lag_lane0',\n",
      "       'lag_lane1', 'lag_lane2', 'lag_lane3', 'lag_lane4', 'lag_acceleration0',\n",
      "       'lag_acceleration1', 'lag_acceleration2', 'lag_acceleration3',\n",
      "       'lag_acceleration4', 'lag_acceleration_lead0', 'lag_acceleration_lead1',\n",
      "       'lag_acceleration_lead2', 'lag_acceleration_lead3',\n",
      "       'lag_acceleration_lead4', 'lag_speed0', 'lag_speed1', 'lag_speed2',\n",
      "       'lag_speed3', 'lag_speed4', 'lag_speed_lead0', 'lag_speed_lead1',\n",
      "       'lag_speed_lead2', 'lag_speed_lead3', 'lag_speed_lead4',\n",
      "       'lag_position_lead0', 'lag_position_lead1', 'lag_position_lead2',\n",
      "       'lag_position_lead3', 'lag_position_lead4', 'lag_position0',\n",
      "       'lag_position1', 'lag_position2', 'lag_position3', 'lag_position4',\n",
      "       'lag_s_headway0', 'lag_s_headway1', 'lag_s_headway2', 'lag_s_headway3',\n",
      "       'lag_s_headway4', 'lag_head', 'lag_lead', 'lag_lane', 'lead01',\n",
      "       'lead02', 'lead03', 'lead04', 'lane01', 'lane02', 'lane03', 'lane04',\n",
      "       'tasks', 'task_index', 'timelag', 'dd', 'idd'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32bad5f",
   "metadata": {},
   "source": [
    "## Variable definition\n",
    "\n",
    "We need to define the variables (as numpy arrays) that we will use in our model.\n",
    "\n",
    "* The arrays can have any name but it is more convenient to use the same name as in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "353b6435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.2664105 ]\n",
      " [-1.34933131]\n",
      " [-2.04013918]\n",
      " ...\n",
      " [ 0.11062106]\n",
      " [-0.18263921]\n",
      " [-0.24633022]]\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "# Variable_name = np.array(data['Variable_name']).reshape(-1, 1)\n",
    "# assume reaction time is 1s\n",
    "Acceleration = np.array(data['Acceleration']).reshape(-1, 1)\n",
    "Speed = np.array(data['Speed']).reshape(-1, 1)\n",
    "Space_headway = np.array(data['lag_s_headway1']).reshape(-1, 1)\n",
    "Relative_speed = np.array(data['lag_speed_lead1']- data['lag_speed1']).reshape(-1, 1)\n",
    "\n",
    "print(Acceleration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448d76d1",
   "metadata": {},
   "source": [
    "##### Define the ID variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d2fca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = np.array(data['ID']) # ID does not need to be reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58da27f",
   "metadata": {},
   "source": [
    "## Model specification\n",
    "\n",
    "We now need to create a function that includes our model.\n",
    "\n",
    "* Python functions are defined as: def *function_name*(parameters):\n",
    "* We end a function as: return *value_to_return*\n",
    "\n",
    "In the current implementation we specify two different functions as:\n",
    "* *function 1* calculates the log likelihood per observations\n",
    "* *function 2* calculates the sum of log likelihood taking as input the result from *function 1*\n",
    "\n",
    "*We define two different functions to be more flexible in the post estimation processing later in the code*\n",
    "\n",
    "We use some python (numpy) functions such '*exp*' or '*log*'. To execute these in the current example, we need to also call numpy; hence, we have *np.exp()* and *np.log()*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a4239e",
   "metadata": {},
   "source": [
    "### Define parameters and starting values\n",
    "\n",
    "Ultimately, we want to estimate the value of some parameters that maximise the likelihood of our observations of the dependent variable.\n",
    "\n",
    "Before starting the estimation process, we need to define some starting values for the parameters to be estimated.\n",
    "\n",
    "* The starting values are usually zeroes\n",
    "* When a parameter is included as a denominator, the starting value cannot be 0 for computational reasons.\n",
    "* However, since we estimate the log of sigma, our starting value can be zero since exp(sigma) can never be absolute zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebc72de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_start = {\"alpha_acc\": 0, \"alpha_dec\": 0, \"beta_acc\": 0, \n",
    "               \"beta_dec\": 0, \"gamma_acc\": 0, \"gamma_dec\": 0,\n",
    "               \"lamda_acc\": 0, \"lamda_dec\": 0, \"sigma_acc\": 0, \"sigma_dec\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75d8db-1da9-4553-b515-300b5eab0ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d69a31b",
   "metadata": {},
   "source": [
    "### Load old parameter estimates results\n",
    "\n",
    "Sometimes, we want to use results from old models as starting values.\n",
    "* To do that, we will load the iteration file from a previous estimation\n",
    "* Please note that only values of parameters with same names with our current model will be copied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f12584eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Activate this cell to load old results ###\n",
    "\n",
    "# # Open old iteration file\n",
    "# betas_old = pd.read_csv('model_name_iterations.csv')\n",
    "\n",
    "# # Keep last row\n",
    "# betas_old = betas_old.tail(1)\n",
    "\n",
    "# # Convert to dictionary\n",
    "# betas_old = betas_old.to_dict(orient='records')[0]\n",
    "\n",
    "# # Copy values from old to start for keys that are common to both dictionaries\n",
    "# betas_start = {k: betas_old[k] for k in betas_start.keys() & betas_old.keys()}\n",
    "\n",
    "# # Delete old estimates\n",
    "# del[betas_old]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aca7ff2",
   "metadata": {},
   "source": [
    "### Function 1: log likelihood (LL)\n",
    "This function calculates the log likelihood per observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "764b666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LL(betas): # betas is a vector with the parameters we want to estimate\n",
    "   \n",
    "    # First let's define the parameters to be estimated.\n",
    "    # The parameter names are imported directly from 'beta_start' that we defined earlier\n",
    "    \n",
    "    for pn in range(len(betas_start.values())):\n",
    "        globals()[np.array(list(betas_start.keys()))[pn]] = betas[pn]\n",
    "\n",
    "    # Then we need to define the main model specification\n",
    "    ai = (alpha_acc * ((Speed+np.exp(-50))**beta_acc)/(Space_headway**gamma_acc)) * (abs(Relative_speed)**lamda_acc)\n",
    "    bi = (alpha_dec * ((Speed+np.exp(-50))**beta_dec)/(Space_headway**gamma_dec)) * (abs(Relative_speed)**lamda_dec)\n",
    "\n",
    "    #######################################################################################\n",
    "    #######################################################################################\n",
    "    \n",
    "    # TASK ALERT #1!! Add proximity to public transportation as independent variable\n",
    "    \n",
    "    # TASK ALERT #2!! Add non-linearities for in the form of b1*x + b2*(x**2)\n",
    "    # Add these non-linearities for proximity to public transport, number of vehicles and \n",
    "    # household size\n",
    "\n",
    "    #######################################################################################\n",
    "    #######################################################################################\n",
    "    \n",
    "    # Then we need to use the probability density function of a normal distribution\n",
    "    # We call the normal density function as norm.pdf(a,b,c) with inputs:\n",
    "        # a: is the dependent variable (Number of trips)\n",
    "        # b: this is our model (fi) which serves as the mean of the normal distribution\n",
    "        # c: this is a parameter that captures the standard deviation of the error term\n",
    "        \n",
    "    # We implement the norm.pdf() as follows:\n",
    "        # Trips: is the number of trips observed in the data\n",
    "        # fi: is the model function that we defined earlier\n",
    "        # sigma: is the standard deviation of the error term.\n",
    "        # Instead of sigma, we estimate the log of sigma (i.e. we take the exponent) to ensure positivity of this term:\n",
    "        # 1 # During estimation the sigma value may go to 0\n",
    "        # 2 # If this happens, estimation may fail.\n",
    "    Pa = norm.pdf(Acceleration, ai, np.exp(sigma_acc))\n",
    "    Pb = norm.pdf(Acceleration, bi, np.exp(sigma_dec))\n",
    "    P = Pa**(0+(Relative_speed>=0)) * Pb**(1-(Relative_speed>=0))\n",
    "    # print(P)\n",
    "    \n",
    "    \n",
    "    ############################################################################################################\n",
    "    ############################################################################################################\n",
    "    # - Now this below is relevant if we have panel data and apply mixing (Do not change this piece of code!) -#\n",
    "    if panel == 1:\n",
    "    # Do it as panel\n",
    "        P = pd.DataFrame(P)\n",
    "        P = pd.concat([pd.Series(ID), pd.DataFrame(P)], axis=1, ignore_index=True)\n",
    "        P.rename(columns={P.columns[0]: 'ID'},inplace=True)\n",
    "    \n",
    "        # We take the product of probabilities per individual per draw and then delete the ID column\n",
    "        P = P.groupby('ID', as_index=False).prod()\n",
    "        P = P.drop('ID', axis=1)\n",
    "   \n",
    "    if mixing == 1:\n",
    "        # We take the average per row to get the average probability per individual (if mixing == 1)\n",
    "        \n",
    "        if panel == 1:\n",
    "            P['mean'] = P.mean(axis=1)\n",
    "            P = np.array(P['mean'])\n",
    "        \n",
    "        if panel == 0:\n",
    "            P = pd.DataFrame(P)\n",
    "            P = pd.concat([pd.Series(ID), pd.DataFrame(P)], axis=1, ignore_index=True)\n",
    "            P.rename(columns={P.columns[0]: 'ID'},inplace=True)\n",
    "    \n",
    "            # We take the product of probabilities per individual per draw and then delete the ID column\n",
    "            P = P.groupby('ID', as_index=False).prod()\n",
    "            P = P.drop('ID', axis=1)\n",
    "            P['mean'] = P.mean(axis=1)\n",
    "            P = np.array(P['mean'])\n",
    "            \n",
    "    P = np.array(P)\n",
    "\n",
    "    ### --- This is where the panel data approach ends. --- ###\n",
    "    ############################################################################################################\n",
    "    ############################################################################################################\n",
    "    \n",
    "    # We then take the log of the density function\n",
    "    logprob = np.log(P)\n",
    "    \n",
    "    return logprob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dc1dcd",
   "metadata": {},
   "source": [
    "### Function 2: sum of log likelihood (SLL)\n",
    "This function simply takes the sum of log likelihood that we calculated with the first function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e74b0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLL(betas):\n",
    "    return -sum(LL(betas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82189c90",
   "metadata": {},
   "source": [
    "## Model estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dfe8f9",
   "metadata": {},
   "source": [
    "### Warnings\n",
    "\n",
    "Sometimes, optimisation procedures may 'overdo' it with warnings during estimation.\n",
    "We can supress these with the piece of code below (not always advisable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2a142356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from scipy.stats import t\n",
    "# with warnings.catch_warnings():\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c84cc3d",
   "metadata": {},
   "source": [
    "### Estimation\n",
    "\n",
    "Now it is finally time to run our estimation command.\n",
    "We use an optimisation algorith called 'BFGS'.\n",
    "\n",
    "**It is advisable not to edit the lines of code below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f5ae316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log likelihood: [-24996.76945136]\n",
      "Current log likelihood: [-23306.25770674]\n",
      "Current log likelihood: [-23152.88282405]\n",
      "Current log likelihood: [-22944.0623558]\n",
      "Current log likelihood: [-22786.13969629]\n",
      "Current log likelihood: [-22638.30327478]\n",
      "Current log likelihood: [-22618.96981057]\n",
      "Current log likelihood: [-22592.6731065]\n",
      "Current log likelihood: [-22482.28361215]\n",
      "Current log likelihood: [-22462.72309787]\n",
      "Current log likelihood: [-22462.19954986]\n",
      "Current log likelihood: [-22441.21291372]\n",
      "Current log likelihood: [-22402.57731738]\n",
      "Current log likelihood: [-22340.85645572]\n",
      "Current log likelihood: [-22318.87079694]\n",
      "Current log likelihood: [-22314.46872735]\n",
      "Current log likelihood: [-22307.8379214]\n",
      "Current log likelihood: [-22303.06070007]\n",
      "Current log likelihood: [-22301.69367274]\n",
      "Current log likelihood: [-22299.7089304]\n",
      "Current log likelihood: [-22297.70801381]\n",
      "Current log likelihood: [-22295.31739583]\n",
      "Current log likelihood: [-22293.0226998]\n",
      "Current log likelihood: [-22291.4552078]\n",
      "Current log likelihood: [-22288.69187666]\n",
      "Current log likelihood: [-22284.36625298]\n",
      "Current log likelihood: [-22280.84188667]\n",
      "Current log likelihood: [-22279.52965793]\n",
      "Current log likelihood: [-22278.67718879]\n",
      "Current log likelihood: [-22277.44473094]\n",
      "Current log likelihood: [-22275.22630123]\n",
      "Current log likelihood: [-22272.03258507]\n",
      "Current log likelihood: [-22271.75461562]\n",
      "Current log likelihood: [-22271.34610174]\n",
      "Current log likelihood: [-22271.08733629]\n",
      "Current log likelihood: [-22271.00711866]\n",
      "Current log likelihood: [-22270.9136873]\n",
      "Current log likelihood: [-22270.79516267]\n",
      "Current log likelihood: [-22270.58554705]\n",
      "Current log likelihood: [-22270.2237031]\n",
      "Current log likelihood: [-22269.64909659]\n",
      "Current log likelihood: [-22268.91213513]\n",
      "Current log likelihood: [-22268.18619348]\n",
      "Current log likelihood: [-22267.11660564]\n",
      "Current log likelihood: [-22266.05184984]\n",
      "Current log likelihood: [-22265.07741597]\n",
      "Current log likelihood: [-22264.67288441]\n",
      "Current log likelihood: [-22264.52405726]\n",
      "Current log likelihood: [-22264.43175128]\n",
      "Current log likelihood: [-22264.38336469]\n",
      "Current log likelihood: [-22264.35287407]\n",
      "Current log likelihood: [-22264.34162552]\n",
      "Current log likelihood: [-22264.33615454]\n",
      "Current log likelihood: [-22264.33542964]\n",
      "Current log likelihood: [-22264.33537075]\n",
      "Current log likelihood: [-22264.33536883]\n",
      "Current log likelihood: [-22264.33536816]\n",
      "Current log likelihood: [-22264.33536816]\n",
      "Current log likelihood: [-22264.33536815]\n",
      "Current log likelihood: [-22264.33536814]\n",
      "Current log likelihood: [-22264.33536813]\n",
      "Current log likelihood: [-22264.33536812]\n",
      "Current log likelihood: [-22264.33536811]\n",
      "Current log likelihood: [-22264.3353681]\n",
      "Current log likelihood: [-22264.33536809]\n",
      "Current log likelihood: [-22264.33536808]\n",
      "Current log likelihood: [-22264.33536805]\n",
      "Current log likelihood: [-22264.335368]\n",
      "Current log likelihood: [-22264.33536792]\n",
      "Current log likelihood: [-22264.33536778]\n",
      "Current log likelihood: [-22264.33536753]\n",
      "Current log likelihood: [-22264.33536707]\n",
      "Current log likelihood: [-22264.33536611]\n",
      "Current log likelihood: [-22264.33536415]\n",
      "Current log likelihood: [-22264.33536091]\n",
      "Current log likelihood: [-22264.33535715]\n",
      "Current log likelihood: [-22264.33535377]\n",
      "Current log likelihood: [-22264.33534817]\n",
      "Current log likelihood: [-22264.33534279]\n",
      "Current log likelihood: [-22264.33534182]\n",
      "Current log likelihood: [-22264.33534064]\n",
      "Current log likelihood: [-22264.33533891]\n",
      "Current log likelihood: [-22264.33533626]\n",
      "Current log likelihood: [-22264.33533188]\n",
      "Current log likelihood: [-22264.33532546]\n",
      "Current log likelihood: [-22264.33531755]\n",
      "Current log likelihood: [-22264.33530895]\n",
      "Current log likelihood: [-22264.33529419]\n",
      "Current log likelihood: [-22264.33527256]\n",
      "Current log likelihood: [-22264.33525415]\n",
      "Current log likelihood: [-22264.33523535]\n",
      "Current log likelihood: [-22264.33520961]\n",
      "Current log likelihood: [-22264.33519328]\n",
      "Current log likelihood: [-22264.33516749]\n",
      "Current log likelihood: [-22264.33512494]\n",
      "Current log likelihood: [-22264.33505061]\n",
      "Current log likelihood: [-22264.33491882]\n",
      "Current log likelihood: [-22264.33473606]\n",
      "Current log likelihood: [-22264.33462244]\n",
      "Current log likelihood: [-22264.33455076]\n",
      "Current log likelihood: [-22264.33453507]\n",
      "Current log likelihood: [-22264.33452511]\n",
      "Current log likelihood: [-22264.33451228]\n",
      "Current log likelihood: [-22264.33450494]\n",
      "Current log likelihood: [-22264.33423217]\n",
      "Current log likelihood: [-22264.33375217]\n",
      "Current log likelihood: [-22264.33321813]\n",
      "Current log likelihood: [-22264.3330887]\n",
      "Current log likelihood: [-22264.33302832]\n",
      "Current log likelihood: [-22264.3330092]\n",
      "Current log likelihood: [-22264.33300617]\n",
      "Current log likelihood: [-22264.33300403]\n",
      "Current log likelihood: [-22264.33300024]\n",
      "Current log likelihood: [-22264.33299437]\n",
      "Current log likelihood: [-22264.33298366]\n",
      "Current log likelihood: [-22264.33296492]\n",
      "Current log likelihood: [-22264.33292854]\n",
      "Current log likelihood: [-22264.33285974]\n",
      "Current log likelihood: [-22264.33273495]\n",
      "Current log likelihood: [-22264.33251167]\n",
      "Current log likelihood: [-22264.33213134]\n",
      "Current log likelihood: [-22264.33148483]\n",
      "Current log likelihood: [-22264.33043616]\n",
      "Current log likelihood: [-22264.32874393]\n",
      "Current log likelihood: [-22264.32586145]\n",
      "Current log likelihood: [-22264.32072668]\n",
      "Current log likelihood: [-22264.31198166]\n",
      "Current log likelihood: [-22264.29875313]\n",
      "Current log likelihood: [-22264.28433088]\n",
      "Current log likelihood: [-22264.26760333]\n",
      "Current log likelihood: [-22264.24182209]\n",
      "Current log likelihood: [-22264.20026206]\n",
      "Current log likelihood: [-22264.12746107]\n",
      "Current log likelihood: [-22263.99451219]\n",
      "Current log likelihood: [-22263.7483659]\n",
      "Current log likelihood: [-22263.29244381]\n",
      "Current log likelihood: [-22262.45476627]\n",
      "Current log likelihood: [-22260.93935748]\n",
      "Current log likelihood: [-22258.2552811]\n",
      "Current log likelihood: [-22253.56590484]\n",
      "Current log likelihood: [-22245.07710977]\n",
      "Current log likelihood: [-22231.68028156]\n",
      "Current log likelihood: [-22210.83782862]\n",
      "Current log likelihood: [-22177.23636494]\n",
      "Current log likelihood: [-22125.33350573]\n",
      "Current log likelihood: [-22039.24511975]\n",
      "Current log likelihood: [-21911.12984407]\n",
      "Current log likelihood: [-21812.87023712]\n",
      "Current log likelihood: [-21768.68518941]\n",
      "Current log likelihood: [-21764.87525433]\n",
      "Current log likelihood: [-21759.59053801]\n",
      "Current log likelihood: [-21757.09215524]\n",
      "Current log likelihood: [-21755.60641035]\n",
      "Current log likelihood: [-21753.16877619]\n",
      "Current log likelihood: [-21749.30630986]\n",
      "Current log likelihood: [-21743.38166757]\n",
      "Current log likelihood: [-21735.23459023]\n",
      "Current log likelihood: [-21725.3223684]\n",
      "Current log likelihood: [-21719.10298192]\n",
      "Current log likelihood: [-21716.26975568]\n",
      "Current log likelihood: [-21715.2489194]\n",
      "Current log likelihood: [-21713.57054247]\n",
      "Current log likelihood: [-21710.92165683]\n",
      "Current log likelihood: [-21708.26905257]\n",
      "Current log likelihood: [-21706.24413899]\n",
      "Current log likelihood: [-21705.24017397]\n",
      "Current log likelihood: [-21703.53235485]\n",
      "Current log likelihood: [-21700.61215313]\n",
      "Current log likelihood: [-21696.21586792]\n",
      "Current log likelihood: [-21690.11625104]\n",
      "Current log likelihood: [-21686.27016985]\n",
      "Current log likelihood: [-21680.82825194]\n",
      "Current log likelihood: [-21674.89153241]\n",
      "Current log likelihood: [-21671.6494991]\n",
      "Current log likelihood: [-21667.26436639]\n",
      "Current log likelihood: [-21664.78894962]\n",
      "Current log likelihood: [-21663.2341461]\n",
      "Current log likelihood: [-21660.83086485]\n",
      "Current log likelihood: [-21659.7563765]\n",
      "Current log likelihood: [-21658.4829629]\n",
      "Current log likelihood: [-21657.74582969]\n",
      "Current log likelihood: [-21657.30264067]\n",
      "Current log likelihood: [-21656.68898412]\n",
      "Current log likelihood: [-21655.98961117]\n",
      "Current log likelihood: [-21654.76891616]\n",
      "Current log likelihood: [-21652.53591603]\n",
      "Current log likelihood: [-21650.96705215]\n",
      "Current log likelihood: [-21648.14321355]\n",
      "Current log likelihood: [-21643.30012029]\n",
      "Current log likelihood: [-21640.59884424]\n",
      "Current log likelihood: [-21636.68703542]\n",
      "Current log likelihood: [-21631.27409221]\n",
      "Current log likelihood: [-21625.40660389]\n",
      "Current log likelihood: [-21615.15262693]\n",
      "Current log likelihood: [-21608.9979325]\n",
      "Current log likelihood: [-21607.88208115]\n",
      "Current log likelihood: [-21605.96151058]\n",
      "Current log likelihood: [-21603.58378827]\n",
      "Current log likelihood: [-21603.0022675]\n",
      "Current log likelihood: [-21602.22007981]\n",
      "Current log likelihood: [-21601.50484768]\n",
      "Current log likelihood: [-21600.92000692]\n",
      "Current log likelihood: [-21600.53631999]\n",
      "Current log likelihood: [-21600.44733923]\n",
      "Current log likelihood: [-21600.42894397]\n",
      "Current log likelihood: [-21600.42474]\n",
      "Current log likelihood: [-21600.42306109]\n",
      "Current log likelihood: [-21600.42219187]\n",
      "Current log likelihood: [-21600.42083724]\n",
      "Current log likelihood: [-21600.41924149]\n",
      "Current log likelihood: [-21600.41824037]\n",
      "Current log likelihood: [-21600.41778068]\n",
      "Current log likelihood: [-21600.41770686]\n",
      "Current log likelihood: [-21600.41770074]\n",
      "Current log likelihood: [-21600.41769862]\n",
      "Current log likelihood: [-21600.4176978]\n",
      "Current log likelihood: [-21600.41769776]\n",
      "Current log likelihood: [-21600.41769763]\n",
      "Current log likelihood: [-21600.41769756]\n",
      "Current log likelihood: [-21600.41769756]\n",
      "Current log likelihood: [-21600.41769756]\n",
      "Current log likelihood: [-21600.41769756]\n",
      "Final log likelihood: -21600.417697556746\n"
     ]
    }
   ],
   "source": [
    "# This will give us the initial loglikelihood value as an output\n",
    "def callback1(betas):\n",
    "    print(\"Current log likelihood:\", -SLL(betas))\n",
    "\n",
    "# This function will allow as to store parameter estimates during iterations\n",
    "# Initialise list to store parameter values\n",
    "parameter_values = [np.array(list(betas_start.values()))]\n",
    "# Then define the function\n",
    "def callback2(betas):    \n",
    "    parameter_values.append(betas)\n",
    "    column_names = list(betas_start.keys())\n",
    "    with open(f'{model_name}_iterations.csv','w',newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(column_names)\n",
    "        writer.writerows(parameter_values)\n",
    "\n",
    "# Now let's combine the two callback functions\n",
    "def combined_callback(betas):\n",
    "    callback1(betas)\n",
    "    callback2(betas)\n",
    "        \n",
    "print(\"Initial log likelihood:\", -SLL(np.array(list(betas_start.values()))))\n",
    "\n",
    "# Choose optimisation routine (preferably BFGS)\n",
    "optimiser = 'BFGS' # BFGS or L-BFGS-B or nelder-mead\n",
    "\n",
    "result = minimize(SLL, np.array(list(betas_start.values())), method=optimiser,callback=combined_callback, \n",
    "                  options={'disp':False}) # ,bounds=bounds1\n",
    "#args = (parameter_values,)\n",
    "print(\"Final log likelihood:\", -result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f05d5",
   "metadata": {},
   "source": [
    "## Post estimation processing\n",
    "\n",
    "We evaluate our parameter estimates using t-ratios (or p-Values).\n",
    "\n",
    "In maximum likelihood estimation, we extract these from the variance-covariance matrix of the parameters.\n",
    "\n",
    "The variance covariance matrix is not readily available but we need to calculate it.\n",
    "\n",
    "This is done with the code below.\n",
    "\n",
    "**DO NOT EDIT THE CHUNK OF CODE BELOW!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bd351453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Hessian, please wait (this may take a while...)\n",
      "... Done!!\n"
     ]
    }
   ],
   "source": [
    "# Vector of parameter estimates\n",
    "parameters = result['x'] \n",
    "\n",
    "# Calculate hessian\n",
    "print(\"Calculating Hessian, please wait (this may take a while...)\")\n",
    "Hess = nd.Hessian(SLL, method = 'forward')\n",
    "hessian = Hess(parameters)\n",
    "inv_hessian = np.linalg.inv(hessian)\n",
    "\n",
    "# Parameter statistics\n",
    "dof = Nobs - len(betas_start) - 1\n",
    "se = np.sqrt(np.diag(inv_hessian)) # Standard errors\n",
    "tratio = parameters/se # t-ratios\n",
    "p_value = (1-t.cdf(np.abs(tratio),dof)) * 2 # p-values\n",
    "\n",
    "\n",
    "# --- Sandwich estimator --- #\n",
    "\n",
    "# The sandwich estimator provides the \"robust\" s.e., t-ratios and p-values.\n",
    "# These should be preferred over the classical parameter statistics.\n",
    "\n",
    "# We first need the gradients at the solution point\n",
    "Grad = nd.Gradient(LL, method = 'forward')\n",
    "gradient = Grad(parameters)\n",
    "\n",
    "# Then we need to calculate the B matrix\n",
    "B = np.array([])\n",
    "for r in range(gradient.shape[0]):\n",
    "    Bm = np.zeros([len(betas_start),len(betas_start)])\n",
    "    gradient0 = gradient[r,:]\n",
    "    for i in range(len(gradient0)):\n",
    "            for j in range(len(gradient0)):\n",
    "                element = gradient0[i]*gradient0[j]\n",
    "                Bm[i][j] = element\n",
    "    if B.size==0:\n",
    "                    B = Bm\n",
    "    else:\n",
    "                    B = B+Bm\n",
    "\n",
    "# Finally we \"sandwich\" the B matrix between the inverese hessian matrices\n",
    "BHHH = (inv_hessian)@(B)@(inv_hessian)\n",
    "\n",
    "print(\"... Done!!\")\n",
    "\n",
    "# Now it is time to calculate some \"robust\" parameter statistics\n",
    "rob_se = np.sqrt(np.diag(BHHH)) # robust standard error\n",
    "rob_tratio = parameters/rob_se # robust t-ratio\n",
    "rob_p_value = (1-t.cdf(np.abs(rob_tratio),dof)) * 2 # robust p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12586d23",
   "metadata": {},
   "source": [
    "## Results\n",
    "Finally, we got our results. Let's print them!\n",
    "\n",
    "The outputs that we receive are:\n",
    "* Estimates: These are the values of our parameters. We must check if the sign is consistent with our expectations\n",
    "* s.e.: Standard errors of the parameters\n",
    "* tratio: t-ratio of the parameters (significant if absolute value > 1.96)\n",
    "* p_value: p-value of the parameters (significant if < 0.05)\n",
    "\n",
    "The parameter statistics also have their **robust** versions. These should be preferred as they are less susceptible to mis-specified models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "38e411cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>s.e.</th>\n",
       "      <th>t-ratio0</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Rob s.e.</th>\n",
       "      <th>Rob t-ratio0</th>\n",
       "      <th>Rob p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha_acc</td>\n",
       "      <td>2.036</td>\n",
       "      <td>0.193</td>\n",
       "      <td>10.526</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.231</td>\n",
       "      <td>8.798</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpha_dec</td>\n",
       "      <td>-2.717</td>\n",
       "      <td>0.274</td>\n",
       "      <td>-9.911</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.356</td>\n",
       "      <td>-7.634</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beta_acc</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.040</td>\n",
       "      <td>7.640</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.045</td>\n",
       "      <td>6.712</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beta_dec</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.036</td>\n",
       "      <td>2.233</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.044</td>\n",
       "      <td>1.832</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gamma_acc</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.047</td>\n",
       "      <td>15.310</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.054</td>\n",
       "      <td>13.288</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gamma_dec</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.386</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.064</td>\n",
       "      <td>11.056</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lamda_acc</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.030</td>\n",
       "      <td>30.128</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.033</td>\n",
       "      <td>27.702</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lamda_dec</td>\n",
       "      <td>1.006</td>\n",
       "      <td>0.027</td>\n",
       "      <td>37.773</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>31.978</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sigma_acc</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-36.131</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-28.766</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sigma_dec</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-30.773</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-23.060</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parameter  Estimate   s.e.  t-ratio0  p-value  Rob s.e.  Rob t-ratio0  \\\n",
       "0  alpha_acc     2.036  0.193    10.526    0.000     0.231         8.798   \n",
       "1  alpha_dec    -2.717  0.274    -9.911    0.000     0.356        -7.634   \n",
       "2   beta_acc     0.304  0.040     7.640    0.000     0.045         6.712   \n",
       "3   beta_dec     0.081  0.036     2.233    0.026     0.044         1.832   \n",
       "4  gamma_acc     0.719  0.047    15.310    0.000     0.054        13.288   \n",
       "5  gamma_dec     0.710  0.049    14.386    0.000     0.064        11.056   \n",
       "6  lamda_acc     0.904  0.030    30.128    0.000     0.033        27.702   \n",
       "7  lamda_dec     1.006  0.027    37.773    0.000     0.031        31.978   \n",
       "8  sigma_acc    -0.263  0.007   -36.131    0.000     0.009       -28.766   \n",
       "9  sigma_dec    -0.230  0.007   -30.773    0.000     0.010       -23.060   \n",
       "\n",
       "   Rob p-value  \n",
       "0        0.000  \n",
       "1        0.000  \n",
       "2        0.000  \n",
       "3        0.067  \n",
       "4        0.000  \n",
       "5        0.000  \n",
       "6        0.000  \n",
       "7        0.000  \n",
       "8        0.000  \n",
       "9        0.000  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrays = np.column_stack((np.array(list(betas_start.keys())),parameters,se,tratio,p_value,rob_se,rob_tratio,rob_p_value))\n",
    "results = pd.DataFrame(arrays, columns = ['Parameter','Estimate','s.e.','t-ratio0','p-value',\n",
    "                                          'Rob s.e.','Rob t-ratio0','Rob p-value'])\n",
    "\n",
    "results[['Estimate','s.e.','t-ratio0','p-value','Rob s.e.','Rob t-ratio0','Rob p-value']] = (\n",
    "results[['Estimate','s.e.','t-ratio0','p-value','Rob s.e.','Rob t-ratio0','Rob p-value']].apply(pd.to_numeric, errors='coerce'))\n",
    "numeric_cols = results.select_dtypes(include='number').columns\n",
    "results[numeric_cols] = results[numeric_cols].round(3)\n",
    "results # print results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d43ec05",
   "metadata": {},
   "source": [
    "## Goodness-of-fit indices\n",
    "\n",
    "Let's calculate some goodness-of-fit indices now (do not edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ebbb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's calculate the GoF indices\n",
    "\n",
    "rho_squared = 1 - ((-result.fun)/(-SLL(np.zeros(len(betas_start)))))\n",
    "adj_rho_squared = 1 - (((-result.fun)-len(betas_start))/(-SLL(np.zeros(len(betas_start)))))\n",
    "\n",
    "AIC = 2*len(betas_start) - 2*(-result.fun)\n",
    "BIC = len(betas_start)*np.log(Nobs) - 2*(-result.fun)\n",
    "\n",
    "LL0t = \"Log likelihood at zeros:\" + str(-SLL(np.zeros(len(betas_start))))\n",
    "LLinit = \"Initial log likelihood:\" + str(-SLL(np.array(list(betas_start.values()))))\n",
    "LLfin = \"Final log likelihood:\" + str(-result.fun)\n",
    "\n",
    "rs1 = \"rho squared=\"+str(rho_squared)\n",
    "rs2 = \"adjusted rho squared=\"+str(adj_rho_squared)\n",
    "ac = \"AIC=\"+str(AIC)\n",
    "bc = \"BIC=\"+str(BIC)\n",
    "\n",
    "# Then let's print the GoF indices\n",
    "\n",
    "print(LL0t)\n",
    "print(LLinit)\n",
    "print(LLfin)\n",
    "\n",
    "print(rs1)\n",
    "print(rs2)\n",
    "print(ac)\n",
    "print(bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c0bc6",
   "metadata": {},
   "source": [
    "## Save output\n",
    "\n",
    "We can save our output using the code below (do not edit):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d92097",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{model_name}_results.txt\", 'w') as f:\n",
    "    f.write(f'{LL0t}\\n')\n",
    "    f.write(f'{LLinit}\\n')\n",
    "    f.write(f'{LLfin}\\n')\n",
    "    f.write(f'{rs1}\\n')\n",
    "    f.write(f'{rs2}\\n')\n",
    "    f.write(f'{ac}\\n')\n",
    "    f.write(f'{bc}\\n')\n",
    "    results.to_csv(f, index=False, sep='\\t')\n",
    "results.to_csv(f'{model_name}_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
