{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb37443",
   "metadata": {},
   "source": [
    "# Car-following model (Base code)\n",
    "\n",
    "This notebook was written by Evangelos Paschalidis (evangelos.paschalidis@epfl.ch) for the Decision-aid methodologies in transportation course at EPFL (http://edu.epfl.ch/coursebook/en/decision-aid-methodologies-in-transportation-CIVIL-557). \n",
    "\n",
    "Please contact before distributing or reusing the material below.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook covers the estimation of a GM car-following model in python with maximum likelihhod estimation:\n",
    "\n",
    "* Load necessary packages\n",
    "* Define variables and parameters to estimate\n",
    "* Model specification\n",
    "* Model output\n",
    "\n",
    "Have a go at working through the notebook. To run a code cell, just click on it (to see a green box around it) and then press the **Run** button at the top! \n",
    "\n",
    "Some cells have blank lines for you to complete. There is always a comment telling you what to do!\n",
    "\n",
    "You can also add a new cell by pressing the **+** button at the top of the page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ad16e",
   "metadata": {},
   "source": [
    "## Load packages\n",
    "\n",
    "Before we estimate the model let's load some packages that we are going to need. When importing a package, it is common to rename it using an abbreviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57a2baa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for data frame processing\n",
    "import numpy as np # for some statistical procedures\n",
    "from scipy.optimize import minimize # optimisation routine for parameter estimation\n",
    "from scipy.stats import norm # normal distribution density function\n",
    "import numdifftools as nd # we use this to calculate t-ratios and p-values\n",
    "import csv # we need this to store our parameters as csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431fb5b4",
   "metadata": {},
   "source": [
    "### Let's give a name to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6900880",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'car_following_model26' # Name we want to give to our model (this is used when saving the output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b1791d",
   "metadata": {},
   "source": [
    "### Panel structure\n",
    "We need to define whether our data is panel (i.e. multiple observations per individual) or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6fc3de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = 1 # switch to 1 if data is panel (any other value if not panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c20c41",
   "metadata": {},
   "source": [
    "### Define if we use mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e417dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixing = 0 # switch to 1 if we apply mixing (any other value if no mixing applied)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e12a2a2",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Now it is time to load the data. We can do that using the piece of code below.\n",
    "\n",
    "**Important!** Make sure the data is in the same folder with the notebook file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be01c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to load the data\n",
    "data = pd.read_table('data26_2.txt')\n",
    "\n",
    "# Number of observations (we need this to caclulate goodness-of-fit indices)\n",
    "Nobs = data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e03b17",
   "metadata": {},
   "source": [
    "## Print the data\n",
    "\n",
    "Let's quickly print the data. Simply type *data* in the field below\n",
    "\n",
    "(If we had opened our data set with a different name e.g. *database*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "176b4f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Position</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>Type</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Lane</th>\n",
       "      <th>Leader</th>\n",
       "      <th>...</th>\n",
       "      <th>lead01</th>\n",
       "      <th>lead02</th>\n",
       "      <th>lead03</th>\n",
       "      <th>lead04</th>\n",
       "      <th>lane01</th>\n",
       "      <th>lane02</th>\n",
       "      <th>lane03</th>\n",
       "      <th>lane04</th>\n",
       "      <th>tasks</th>\n",
       "      <th>task_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>125.54</td>\n",
       "      <td>4.65</td>\n",
       "      <td>1.82</td>\n",
       "      <td>Car</td>\n",
       "      <td>7.29</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>117.87</td>\n",
       "      <td>4.65</td>\n",
       "      <td>1.82</td>\n",
       "      <td>Car</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.69</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>109.29</td>\n",
       "      <td>4.65</td>\n",
       "      <td>1.82</td>\n",
       "      <td>Car</td>\n",
       "      <td>8.53</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>100.74</td>\n",
       "      <td>4.65</td>\n",
       "      <td>1.82</td>\n",
       "      <td>Car</td>\n",
       "      <td>8.38</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>92.60</td>\n",
       "      <td>4.65</td>\n",
       "      <td>1.82</td>\n",
       "      <td>Car</td>\n",
       "      <td>8.07</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23714</th>\n",
       "      <td>2398</td>\n",
       "      <td>988</td>\n",
       "      <td>154.22</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.72</td>\n",
       "      <td>Car</td>\n",
       "      <td>22.85</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>2394</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23715</th>\n",
       "      <td>2398</td>\n",
       "      <td>989</td>\n",
       "      <td>131.62</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.72</td>\n",
       "      <td>Car</td>\n",
       "      <td>22.32</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>2394</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23716</th>\n",
       "      <td>2398</td>\n",
       "      <td>990</td>\n",
       "      <td>109.54</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.72</td>\n",
       "      <td>Car</td>\n",
       "      <td>21.84</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>2</td>\n",
       "      <td>2394</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23717</th>\n",
       "      <td>2398</td>\n",
       "      <td>991</td>\n",
       "      <td>87.94</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.72</td>\n",
       "      <td>Car</td>\n",
       "      <td>21.54</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>2</td>\n",
       "      <td>2394</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23718</th>\n",
       "      <td>2398</td>\n",
       "      <td>992</td>\n",
       "      <td>66.40</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.72</td>\n",
       "      <td>Car</td>\n",
       "      <td>21.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>2394</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23719 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Time  Position  Length  Width Type  Speed  Acceleration  Lane  \\\n",
       "0        40     4    125.54    4.65   1.82  Car   7.29          0.85     3   \n",
       "1        40     5    117.87    4.65   1.82  Car   8.12          0.69     3   \n",
       "2        40     6    109.29    4.65   1.82  Car   8.53          0.08     3   \n",
       "3        40     7    100.74    4.65   1.82  Car   8.38         -0.31     3   \n",
       "4        40     8     92.60    4.65   1.82  Car   8.07         -0.23     3   \n",
       "...     ...   ...       ...     ...    ...  ...    ...           ...   ...   \n",
       "23714  2398   988    154.22    3.54   1.72  Car  22.85         -0.52     2   \n",
       "23715  2398   989    131.62    3.54   1.72  Car  22.32         -0.52     2   \n",
       "23716  2398   990    109.54    3.54   1.72  Car  21.84         -0.40     2   \n",
       "23717  2398   991     87.94    3.54   1.72  Car  21.54         -0.19     2   \n",
       "23718  2398   992     66.40    3.54   1.72  Car  21.44          0.01     2   \n",
       "\n",
       "       Leader  ...  lead01  lead02  lead03  lead04  lane01  lane02  lane03  \\\n",
       "0          34  ...       1       1       1     NaN       1       1       1   \n",
       "1          34  ...       1       1       1     1.0       1       1       1   \n",
       "2          34  ...       1       1       1     1.0       1       1       1   \n",
       "3          34  ...       1       1       1     1.0       1       1       1   \n",
       "4          34  ...       1       1       1     1.0       1       1       1   \n",
       "...       ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "23714    2394  ...       1       1       1     1.0       1       1       1   \n",
       "23715    2394  ...       1       1       1     1.0       1       1       1   \n",
       "23716    2394  ...       1       1       1     1.0       1       1       1   \n",
       "23717    2394  ...       1       1       1     1.0       1       1       1   \n",
       "23718    2394  ...       1       1       1     1.0       1       1       1   \n",
       "\n",
       "       lane04  tasks  task_index  \n",
       "0         NaN     13           1  \n",
       "1         1.0     13           2  \n",
       "2         1.0     13           3  \n",
       "3         1.0     13           4  \n",
       "4         1.0     13           5  \n",
       "...       ...    ...         ...  \n",
       "23714     1.0     13           9  \n",
       "23715     1.0     13          10  \n",
       "23716     1.0     13          11  \n",
       "23717     1.0     13          12  \n",
       "23718     1.0     13          13  \n",
       "\n",
       "[23719 rows x 79 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type \"data\" in this field (without the quotation) and run the cell (Shift + return)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcff136",
   "metadata": {},
   "source": [
    "## Print the variable names (columns)\n",
    "\n",
    "We can also print the variable names only using the piece of code below\n",
    "\n",
    "* This is useful during model specification to easily access the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e385d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Time', 'Position', 'Length', 'Width', 'Type', 'Speed',\n",
      "       'Acceleration', 'Lane', 'Leader', 'Follower', 'Space_headway',\n",
      "       'Time_headway', 'Acceleration_lead', 'Speed_lead', 'Position_lead',\n",
      "       'Density', 'distanceToEnd', 'Speed_test', 'lane_change', 'lead_change',\n",
      "       'lag_leader0', 'lag_leader1', 'lag_leader2', 'lag_leader3',\n",
      "       'lag_leader4', 'lag_lane0', 'lag_lane1', 'lag_lane2', 'lag_lane3',\n",
      "       'lag_lane4', 'lag_acceleration0', 'lag_acceleration1',\n",
      "       'lag_acceleration2', 'lag_acceleration3', 'lag_acceleration4',\n",
      "       'lag_acceleration_lead0', 'lag_acceleration_lead1',\n",
      "       'lag_acceleration_lead2', 'lag_acceleration_lead3',\n",
      "       'lag_acceleration_lead4', 'lag_speed0', 'lag_speed1', 'lag_speed2',\n",
      "       'lag_speed3', 'lag_speed4', 'lag_speed_lead0', 'lag_speed_lead1',\n",
      "       'lag_speed_lead2', 'lag_speed_lead3', 'lag_speed_lead4',\n",
      "       'lag_position_lead0', 'lag_position_lead1', 'lag_position_lead2',\n",
      "       'lag_position_lead3', 'lag_position_lead4', 'lag_position0',\n",
      "       'lag_position1', 'lag_position2', 'lag_position3', 'lag_position4',\n",
      "       'lag_s_headway0', 'lag_s_headway1', 'lag_s_headway2', 'lag_s_headway3',\n",
      "       'lag_s_headway4', 'lag_head', 'lag_lead', 'lag_lane', 'lead01',\n",
      "       'lead02', 'lead03', 'lead04', 'lane01', 'lane02', 'lane03', 'lane04',\n",
      "       'tasks', 'task_index'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d70fd3",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "* It may be the case that our data do not include all variables required for modelling.\n",
    "* In this case we must generate the additional variables that we need"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a5837b",
   "metadata": {},
   "source": [
    "### Variable creation\n",
    "\n",
    "* Let's create a \"running task\" variable, else a counter for the observations of each driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e98d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['running_task'] = data.groupby(['ID']).cumcount()+1 # counter of observations per individual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32bad5f",
   "metadata": {},
   "source": [
    "## Variable definition\n",
    "\n",
    "We need to define the variables (as numpy arrays) that we will use in our model.\n",
    "\n",
    "* The arrays can have any name but it is more convenient to use the same name as in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "353b6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "# Variable_name = np.array(data['Variable_name']).reshape(-1, 1)\n",
    "\n",
    "running_task = np.array(data['running_task']).reshape(-1, 1)\n",
    "Acceleration = np.array(data['Acceleration']).reshape(-1, 1)\n",
    "Speed = np.array(data['Speed']).reshape(-1, 1)\n",
    "Space_headway = np.array(data['Space_headway']).reshape(-1, 1)\n",
    "Speed_lead = np.array(data['Speed_lead']).reshape(-1, 1)\n",
    "Acceleration_lead = np.array(data['Acceleration_lead']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50faec6a",
   "metadata": {},
   "source": [
    "#### Define the ID variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17bdaa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = np.array(data['ID']) # ID does not need to be reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58da27f",
   "metadata": {},
   "source": [
    "## Model specification\n",
    "\n",
    "We now need to create a function that includes our model.\n",
    "\n",
    "* Python functions are defined as: def *function_name*(parameters):\n",
    "* We end a function as: return *value_to_return*\n",
    "\n",
    "In the current implementation we specify two different functions as:\n",
    "* *function 1* calculates the log likelihood per observations\n",
    "* *function 2* calculates the sum of log likelihood taking as input the result from *function 1*\n",
    "\n",
    "*We define two different functions to be more flexible in the post estimation processing later in the code*\n",
    "\n",
    "We use some python (numpy) functions such '*exp*' or '*log*'. To execute these in the current example, we need to also call numpy; hence, we have *np.exp()* and *np.log()*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a4239e",
   "metadata": {},
   "source": [
    "### Define parameters and starting values\n",
    "\n",
    "Ultimately, we want to estimate the value of some parameters that maximise the likelihood of our observations of the dependent variable.\n",
    "\n",
    "Before starting the estimation process, we need to define some starting values for the parameters to be estimated.\n",
    "\n",
    "* The starting values are usually zeroes\n",
    "* When a parameter is included as a denominator, the starting value cannot be 0 for computational reasons.\n",
    "* However, since we estimate the log of sigma, our starting value can be zero since exp(sigma) can never be absolute zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebc72de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_start = {\n",
    "               \"alpha_acc\":0, # Acceleration constant parameter\n",
    "               \"alpha_dec\":0, # Deceleration constant parameter\n",
    "               \"beta_acc\":0,  # Speed (acceleration regime) parameter\n",
    "               \"beta_dec\":0,  # Speed (deceleration regime) parameter\n",
    "               \"gamma_acc\":0, # Space headway (acceleration regime) parameter\n",
    "               \"gamma_dec\":0, # Space headway (deceleration regime) parameter\n",
    "               \"lamda_acc\":0, # Relative speed (acceleration regime) parameter\n",
    "               \"lamda_dec\":0, # Relative speed (deceleration regime) parameter\n",
    "               \"sigma_acc\":0, # Std deviation (acceleration regime) parameter\n",
    "               \"sigma_dec\":0  # Std deviation (deceleration regime) parameter\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0db5a9c",
   "metadata": {},
   "source": [
    "### Load old parameter estimates results\n",
    "\n",
    "Sometimes, we want to use results from old models as starting values.\n",
    "* To do that, we will load the iteration file from a previous estimation\n",
    "* Please note that only values of parameters with same names with our current model will be copied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ac7f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Activate this cell to load old results ###\n",
    "\n",
    "# # Open old iteration file\n",
    "# betas_old = pd.read_csv('model_name_iterations.csv')\n",
    "\n",
    "# # Keep last row\n",
    "# betas_old = betas_old.tail(1)\n",
    "\n",
    "# # Convert to dictionary\n",
    "# betas_old = betas_old.to_dict(orient='records')[0]\n",
    "\n",
    "# # Copy values from old to start for keys that are common to both dictionaries\n",
    "# betas_start = {k: betas_old[k] for k in betas_start.keys() & betas_old.keys()}\n",
    "\n",
    "# # Delete old estimates\n",
    "# del[betas_old]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aca7ff2",
   "metadata": {},
   "source": [
    "### Function 1: log likelihood (LL)\n",
    "This function calculates the log likelihood per observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "764b666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LL(betas): # betas is a vector with the parameters we want to estimate\n",
    "   \n",
    "    # First let's define the parameters to be estimated.\n",
    "    # The parameter names are imported directly from 'beta_start' that we defined earlier\n",
    "    \n",
    "    for pn in range(len(betas_start.values())):\n",
    "        globals()[np.array(list(betas_start.keys()))[pn]] = betas[pn]\n",
    "\n",
    "    # Car-following model specification\n",
    "\n",
    "    # BE CAREFUL!! Below we add a small correction term (np.exp(-50)) to speed and relative speed.\n",
    "    # This correction is included to avoid estimation issues if the value of the independent variables is 0.\n",
    "    \n",
    "    # Sensitivity term\n",
    "    sensitivity_acc = alpha_acc*((Speed+np.exp(-50))**beta_acc)/(Space_headway**gamma_acc)\n",
    "    sensitivity_dec = alpha_dec*((Speed+np.exp(-50))**beta_dec)/(Space_headway**gamma_dec)\n",
    "\n",
    "    # Stimulus term\n",
    "    stimulus_acc = np.abs(Speed_lead - Speed + np.exp(-50))**lamda_acc\n",
    "    stimulus_dec = np.abs(Speed_lead - Speed + np.exp(-50))**lamda_dec\n",
    "\n",
    "    # Acceleration - deceleration means\n",
    "    acc = sensitivity_acc*stimulus_acc\n",
    "    dec = sensitivity_dec*stimulus_dec\n",
    "\n",
    "    # Density functions for acceleration and deceleration\n",
    "    pdf_acc = norm.pdf(Acceleration,acc,np.exp(sigma_acc))\n",
    "    pdf_dec = norm.pdf(Acceleration,dec,np.exp(sigma_dec))\n",
    "    \n",
    "    # Combined probability of acceleration and deceleration regimes\n",
    "    P = pdf_acc*(Speed_lead - Speed>=0)+pdf_dec*(Speed_lead - Speed<0)\n",
    "    \n",
    "    ############################################################################################################\n",
    "    # - Now this below is relevant if we have panel data and apply mixing (Do not change this piece of code!) -#\n",
    "    if panel == 1:\n",
    "    # Do it as panel\n",
    "        P = pd.DataFrame(P)\n",
    "        P = pd.concat([pd.Series(ID), pd.DataFrame(P)], axis=1, ignore_index=True)\n",
    "        P.rename(columns={P.columns[0]: 'ID'},inplace=True)\n",
    "    \n",
    "        # We take the product of probabilities per individual per draw and then delete the ID column\n",
    "        P = P.groupby('ID', as_index=False).prod()\n",
    "        P = P.drop('ID', axis=1)\n",
    "   \n",
    "    if mixing == 1:\n",
    "        # We take the average per row to get the average probability per individual (if mixing == 1)\n",
    "        \n",
    "        if panel == 1:\n",
    "            P['mean'] = P.mean(axis=1)\n",
    "            P = np.array(P['mean'])\n",
    "        \n",
    "        if panel == 0:\n",
    "            P = pd.DataFrame(P)\n",
    "            P = pd.concat([pd.Series(ID), pd.DataFrame(P)], axis=1, ignore_index=True)\n",
    "            P.rename(columns={P.columns[0]: 'ID'},inplace=True)\n",
    "    \n",
    "            # We take the product of probabilities per individual per draw and then delete the ID column\n",
    "            P = P.groupby('ID', as_index=False).prod()\n",
    "            P = P.drop('ID', axis=1)\n",
    "            P['mean'] = P.mean(axis=1)\n",
    "            P = np.array(P['mean'])\n",
    "            \n",
    "    P = np.array(P)\n",
    "    ### --- This is where the panel data approach ends. --- ###\n",
    "    ############################################################################################################\n",
    "    \n",
    "    # We then take the log of the density function\n",
    "    logprob = np.log(P)\n",
    "    \n",
    "    return logprob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dc1dcd",
   "metadata": {},
   "source": [
    "### Function 2: sum of log likelihood (SLL)\n",
    "This function simply takes the sum of log likelihood that we calculated with the first function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e74b0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SLL(betas):\n",
    "    return -sum(LL(betas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82189c90",
   "metadata": {},
   "source": [
    "## Model estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dfe8f9",
   "metadata": {},
   "source": [
    "### Warnings\n",
    "\n",
    "Sometimes, optimisation procedures may 'overdo' it with warnings during estimation.\n",
    "We can supress these with the piece of code below (not always advisable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a142356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from scipy.stats import t\n",
    "# with warnings.catch_warnings():\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c84cc3d",
   "metadata": {},
   "source": [
    "### Estimation\n",
    "\n",
    "Now it is finally time to run our estimation command.\n",
    "We use an optimisation algorith called 'BFGS'.\n",
    "\n",
    "**It is advisable not to edit the lines of code below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f5ae316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log likelihood: [-25106.78216908]\n",
      "Current log likelihood: [-25082.87546349]\n",
      "Current log likelihood: [-21179.5807546]\n",
      "Current log likelihood: [-18781.56889559]\n",
      "Current log likelihood: [-18412.24961475]\n",
      "Current log likelihood: [-17993.4353951]\n",
      "Current log likelihood: [-16398.57598174]\n",
      "Current log likelihood: [-15959.74142902]\n",
      "Current log likelihood: [-15943.59638905]\n",
      "Current log likelihood: [-15739.3315784]\n",
      "Current log likelihood: [-15727.56635988]\n",
      "Current log likelihood: [-15614.89185968]\n",
      "Current log likelihood: [-15399.05162373]\n",
      "Current log likelihood: [-14998.95298428]\n",
      "Current log likelihood: [-14390.48187189]\n",
      "Current log likelihood: [-14127.49503776]\n",
      "Current log likelihood: [-13991.0604782]\n",
      "Current log likelihood: [-13822.9679408]\n",
      "Current log likelihood: [-13742.2294102]\n",
      "Current log likelihood: [-13729.6705359]\n",
      "Current log likelihood: [-13712.23504994]\n",
      "Current log likelihood: [-13693.03006561]\n",
      "Current log likelihood: [-13660.52328082]\n",
      "Current log likelihood: [-13611.13086303]\n",
      "Current log likelihood: [-13569.60171986]\n",
      "Current log likelihood: [-13532.71404467]\n",
      "Current log likelihood: [-13486.22586105]\n",
      "Current log likelihood: [-13453.33958719]\n",
      "Current log likelihood: [-13433.08980281]\n",
      "Current log likelihood: [-13420.37676401]\n",
      "Current log likelihood: [-13409.84076881]\n",
      "Current log likelihood: [-13402.11092739]\n",
      "Current log likelihood: [-13387.94078278]\n",
      "Current log likelihood: [-13361.43363661]\n",
      "Current log likelihood: [-13313.75252902]\n",
      "Current log likelihood: [-13241.6793521]\n",
      "Current log likelihood: [-13160.23181406]\n",
      "Current log likelihood: [-13125.20372105]\n",
      "Current log likelihood: [-13106.07792048]\n",
      "Current log likelihood: [-13098.76353259]\n",
      "Current log likelihood: [-13097.69693331]\n",
      "Current log likelihood: [-13097.4666252]\n",
      "Current log likelihood: [-13097.34104776]\n",
      "Current log likelihood: [-13097.13165779]\n",
      "Current log likelihood: [-13096.76874017]\n",
      "Current log likelihood: [-13096.15319211]\n",
      "Current log likelihood: [-13095.21053175]\n",
      "Current log likelihood: [-13094.33370147]\n",
      "Current log likelihood: [-13093.9086942]\n",
      "Current log likelihood: [-13093.81906833]\n",
      "Current log likelihood: [-13093.80099285]\n",
      "Current log likelihood: [-13093.77006533]\n",
      "Current log likelihood: [-13093.71499477]\n",
      "Current log likelihood: [-13093.61487464]\n",
      "Current log likelihood: [-13093.43151019]\n",
      "Current log likelihood: [-13093.09648156]\n",
      "Current log likelihood: [-13092.48928861]\n",
      "Current log likelihood: [-13091.40193799]\n",
      "Current log likelihood: [-13089.47448494]\n",
      "Current log likelihood: [-13086.06524278]\n",
      "Current log likelihood: [-13080.10358057]\n",
      "Current log likelihood: [-13071.29991057]\n",
      "Current log likelihood: [-13058.84400169]\n",
      "Current log likelihood: [-13035.78298577]\n",
      "Current log likelihood: [-13018.88360357]\n",
      "Current log likelihood: [-12988.09030138]\n",
      "Current log likelihood: [-12936.7582483]\n",
      "Current log likelihood: [-12902.09284193]\n",
      "Current log likelihood: [-12858.79134411]\n",
      "Current log likelihood: [-12851.87208623]\n",
      "Current log likelihood: [-12844.81893513]\n",
      "Current log likelihood: [-12840.98871432]\n",
      "Current log likelihood: [-12837.71266082]\n",
      "Current log likelihood: [-12835.18573886]\n",
      "Current log likelihood: [-12834.23874773]\n",
      "Current log likelihood: [-12832.90822616]\n",
      "Current log likelihood: [-12832.22422022]\n",
      "Current log likelihood: [-12831.9839663]\n",
      "Current log likelihood: [-12831.77973253]\n",
      "Current log likelihood: [-12831.4764422]\n",
      "Current log likelihood: [-12831.16318599]\n",
      "Current log likelihood: [-12830.67805735]\n",
      "Current log likelihood: [-12830.04121753]\n",
      "Current log likelihood: [-12829.7286582]\n",
      "Current log likelihood: [-12829.68194798]\n",
      "Current log likelihood: [-12829.67886202]\n",
      "Current log likelihood: [-12829.67811042]\n",
      "Current log likelihood: [-12829.67794749]\n",
      "Current log likelihood: [-12829.67792662]\n",
      "Current log likelihood: [-12829.67792582]\n",
      "Current log likelihood: [-12829.6779258]\n",
      "Current log likelihood: [-12829.6779258]\n",
      "Current log likelihood: [-12829.6779258]\n",
      "Current log likelihood: [-12829.6779258]\n",
      "Current log likelihood: [-12829.6779258]\n",
      "Current log likelihood: [-12829.6779258]\n",
      "Current log likelihood: [-12829.6779258]\n",
      "Current log likelihood: [-12829.6779258]\n",
      "Current log likelihood: [-12829.6779258]\n",
      "Current log likelihood: [-12829.6779258]\n",
      "Current log likelihood: [-12829.6779258]\n",
      "Current log likelihood: [-12829.67792579]\n",
      "Current log likelihood: [-12829.67792579]\n",
      "Current log likelihood: [-12829.67792579]\n",
      "Current log likelihood: [-12829.67792579]\n",
      "Current log likelihood: [-12829.67792578]\n",
      "Current log likelihood: [-12829.67792578]\n",
      "Current log likelihood: [-12829.67792578]\n",
      "Current log likelihood: [-12829.67792577]\n",
      "Current log likelihood: [-12829.67792575]\n",
      "Current log likelihood: [-12829.67792573]\n",
      "Current log likelihood: [-12829.67792571]\n",
      "Current log likelihood: [-12829.67792567]\n",
      "Current log likelihood: [-12829.6779256]\n",
      "Current log likelihood: [-12829.67792551]\n",
      "Current log likelihood: [-12829.6779255]\n",
      "Current log likelihood: [-12829.67792547]\n",
      "Current log likelihood: [-12829.67792542]\n",
      "Current log likelihood: [-12829.6779254]\n",
      "Current log likelihood: [-12829.67792537]\n",
      "Current log likelihood: [-12829.67792534]\n",
      "Current log likelihood: [-12829.67792529]\n",
      "Current log likelihood: [-12829.67792524]\n",
      "Current log likelihood: [-12829.67792515]\n",
      "Current log likelihood: [-12829.67792499]\n",
      "Current log likelihood: [-12829.67792474]\n",
      "Current log likelihood: [-12829.67792433]\n",
      "Current log likelihood: [-12829.67792366]\n",
      "Current log likelihood: [-12829.67792254]\n",
      "Current log likelihood: [-12829.67792052]\n",
      "Current log likelihood: [-12829.67791686]\n",
      "Current log likelihood: [-12829.67791024]\n",
      "Current log likelihood: [-12829.67789846]\n",
      "Current log likelihood: [-12829.6778783]\n",
      "Current log likelihood: [-12829.677846]\n",
      "Current log likelihood: [-12829.67779612]\n",
      "Current log likelihood: [-12829.67774139]\n",
      "Current log likelihood: [-12829.67770196]\n",
      "Current log likelihood: [-12829.67768834]\n",
      "Current log likelihood: [-12829.67768701]\n",
      "Current log likelihood: [-12829.67768627]\n",
      "Current log likelihood: [-12829.67768551]\n",
      "Current log likelihood: [-12829.6776841]\n",
      "Current log likelihood: [-12829.67768161]\n",
      "Current log likelihood: [-12829.67767751]\n",
      "Current log likelihood: [-12829.67767183]\n",
      "Current log likelihood: [-12829.67766694]\n",
      "Current log likelihood: [-12829.67765829]\n",
      "Current log likelihood: [-12829.67764283]\n",
      "Current log likelihood: [-12829.67761535]\n",
      "Current log likelihood: [-12829.67756803]\n",
      "Current log likelihood: [-12829.67748681]\n",
      "Current log likelihood: [-12829.67734791]\n",
      "Current log likelihood: [-12829.67710753]\n",
      "Current log likelihood: [-12829.67668296]\n",
      "Current log likelihood: [-12829.67592375]\n",
      "Current log likelihood: [-12829.67455685]\n",
      "Current log likelihood: [-12829.67209889]\n",
      "Current log likelihood: [-12829.66770563]\n",
      "Current log likelihood: [-12829.65992905]\n",
      "Current log likelihood: [-12829.64632306]\n",
      "Current log likelihood: [-12829.62277441]\n",
      "Current log likelihood: [-12829.58235772]\n",
      "Current log likelihood: [-12829.51354965]\n",
      "Current log likelihood: [-12829.39830313]\n",
      "Current log likelihood: [-12829.21369231]\n",
      "Current log likelihood: [-12828.95487072]\n",
      "Current log likelihood: [-12828.78020854]\n",
      "Current log likelihood: [-12828.69062439]\n",
      "Current log likelihood: [-12828.68077025]\n",
      "Current log likelihood: [-12828.68010964]\n",
      "Current log likelihood: [-12828.68007337]\n",
      "Current log likelihood: [-12828.68007]\n",
      "Current log likelihood: [-12828.68006934]\n",
      "Current log likelihood: [-12828.68006922]\n",
      "Current log likelihood: [-12828.6800692]\n",
      "Current log likelihood: [-12828.6800692]\n",
      "Current log likelihood: [-12828.6800692]\n",
      "Current log likelihood: [-12828.6800692]\n",
      "Current log likelihood: [-12828.6800692]\n",
      "Current log likelihood: [-12828.6800692]\n",
      "Current log likelihood: [-12828.6800692]\n",
      "Current log likelihood: [-12828.6800692]\n",
      "Final log likelihood: -12828.680069196193\n"
     ]
    }
   ],
   "source": [
    "# This will give us the initial loglikelihood value as an output\n",
    "def callback1(betas):\n",
    "    print(\"Current log likelihood:\", -SLL(betas))\n",
    "\n",
    "# This function will allow as to store parameter estimates during iterations\n",
    "# Initialise list to store parameter values\n",
    "parameter_values = [np.array(list(betas_start.values()))]\n",
    "# Then define the function\n",
    "def callback2(betas):    \n",
    "    parameter_values.append(betas)\n",
    "    column_names = list(betas_start.keys())\n",
    "    with open(f'{model_name}_iterations.csv','w',newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(column_names)\n",
    "        writer.writerows(parameter_values)\n",
    "\n",
    "# Now let's combine the two callback functions\n",
    "def combined_callback(betas):\n",
    "    callback1(betas)\n",
    "    callback2(betas)\n",
    "        \n",
    "print(\"Initial log likelihood:\", -SLL(np.array(list(betas_start.values()))))\n",
    "\n",
    "# Choose optimisation routine (preferably BFGS)\n",
    "optimiser = 'BFGS' # BFGS or L-BFGS-B or nelder-mead\n",
    "\n",
    "result = minimize(SLL, np.array(list(betas_start.values())), method=optimiser,callback=combined_callback, \n",
    "                  options={'disp':False}) # ,bounds=bounds1\n",
    "#args = (parameter_values,)\n",
    "print(\"Final log likelihood:\", -result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4f05d5",
   "metadata": {},
   "source": [
    "## Post estimation processing\n",
    "\n",
    "We evaluate our parameter estimates using t-ratios (or p-Values).\n",
    "\n",
    "In maximum likelihood estimation, we extract these from the variance-covariance matrix of the parameters.\n",
    "\n",
    "The variance covariance matrix is not readily available but we need to calculate it.\n",
    "\n",
    "This is done with the code below.\n",
    "\n",
    "**DO NOT EDIT THE CHUNK OF CODE BELOW!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd351453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Hessian, please wait (this may take a while...)\n",
      "... Done!!\n"
     ]
    }
   ],
   "source": [
    "# Vector of parameter estimates\n",
    "parameters = result['x'] \n",
    "\n",
    "# Calculate hessian\n",
    "print(\"Calculating Hessian, please wait (this may take a while...)\")\n",
    "Hess = nd.Hessian(SLL,method='forward')\n",
    "hessian = Hess(parameters)\n",
    "inv_hessian = np.linalg.inv(hessian)\n",
    "\n",
    "# Parameter statistics\n",
    "dof = Nobs - len(betas_start) - 1\n",
    "se = np.sqrt(np.diag(inv_hessian)) # Standard errors\n",
    "tratio = parameters/se # t-ratios\n",
    "p_value = (1-t.cdf(np.abs(tratio),dof)) * 2 # p-values\n",
    "\n",
    "\n",
    "# --- Sandwich estimator --- #\n",
    "\n",
    "# The sandwich estimator provides the \"robust\" s.e., t-ratios and p-values.\n",
    "# These should be preferred over the classical parameter statistics.\n",
    "\n",
    "# We first need the gradients at the solution point\n",
    "Grad = nd.Gradient(LL,method='forward')\n",
    "gradient = Grad(parameters)\n",
    "\n",
    "# Then we need to calculate the B matrix\n",
    "B = np.array([])\n",
    "for r in range(gradient.shape[0]):\n",
    "    Bm = np.zeros([len(betas_start),len(betas_start)])\n",
    "    gradient0 = gradient[r,:]\n",
    "    for i in range(len(gradient0)):\n",
    "            for j in range(len(gradient0)):\n",
    "                element = gradient0[i]*gradient0[j]\n",
    "                Bm[i][j] = element\n",
    "    if B.size==0:\n",
    "                    B = Bm\n",
    "    else:\n",
    "                    B = B+Bm\n",
    "\n",
    "# Finally we \"sandwich\" the B matrix between the inverese hessian matrices\n",
    "BHHH = (inv_hessian)@(B)@(inv_hessian)\n",
    "\n",
    "print(\"... Done!!\")\n",
    "\n",
    "# Now it is time to calculate some \"robust\" parameter statistics\n",
    "rob_se = np.sqrt(np.diag(BHHH)) # robust standard error\n",
    "rob_tratio = parameters/rob_se # robust t-ratio\n",
    "rob_p_value = (1-t.cdf(np.abs(rob_tratio),dof)) * 2 # robust p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12586d23",
   "metadata": {},
   "source": [
    "## Results\n",
    "Finally, we got our results. Let's print them!\n",
    "\n",
    "The outputs that we receive are:\n",
    "* Estimates: These are the values of our parameters. We must check if the sign is consistent with our expectations\n",
    "* s.e.: Standard errors of the parameters\n",
    "* tratio: t-ratio of the parameters (significant if absolute value > 1.96)\n",
    "* p_value: p-value of the parameters (significant if < 0.05)\n",
    "\n",
    "The parameter statistics also have their **robust** versions. These should be preferred as they are less susceptible to mis-specified models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38e411cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Estimate</th>\n",
       "      <th>s.e.</th>\n",
       "      <th>t-ratio0</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Rob s.e.</th>\n",
       "      <th>Rob t-ratio0</th>\n",
       "      <th>Rob p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpha_acc</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.072</td>\n",
       "      <td>9.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.145</td>\n",
       "      <td>4.952</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alpha_dec</td>\n",
       "      <td>-1.411</td>\n",
       "      <td>0.111</td>\n",
       "      <td>-12.728</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.348</td>\n",
       "      <td>-4.054</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beta_acc</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-1.413</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-1.193</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beta_dec</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.029</td>\n",
       "      <td>1.766</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gamma_acc</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.031</td>\n",
       "      <td>10.966</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.063</td>\n",
       "      <td>5.382</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gamma_dec</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.018</td>\n",
       "      <td>28.153</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.069</td>\n",
       "      <td>7.361</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lamda_acc</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.020</td>\n",
       "      <td>28.694</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.036</td>\n",
       "      <td>16.090</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lamda_dec</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.014</td>\n",
       "      <td>57.807</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.044</td>\n",
       "      <td>18.567</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sigma_acc</td>\n",
       "      <td>-0.964</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-146.105</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-51.596</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sigma_dec</td>\n",
       "      <td>-0.796</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-124.402</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-38.583</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parameter  Estimate   s.e.  t-ratio0  p-value  Rob s.e.  Rob t-ratio0  \\\n",
       "0  alpha_acc     0.717  0.072     9.999    0.000     0.145         4.952   \n",
       "1  alpha_dec    -1.411  0.111   -12.728    0.000     0.348        -4.054   \n",
       "2   beta_acc    -0.010  0.007    -1.413    0.158     0.008        -1.193   \n",
       "3   beta_dec     0.052  0.029     1.766    0.077     0.087         0.596   \n",
       "4  gamma_acc     0.340  0.031    10.966    0.000     0.063         5.382   \n",
       "5  gamma_dec     0.506  0.018    28.153    0.000     0.069         7.361   \n",
       "6  lamda_acc     0.578  0.020    28.694    0.000     0.036        16.090   \n",
       "7  lamda_dec     0.810  0.014    57.807    0.000     0.044        18.567   \n",
       "8  sigma_acc    -0.964  0.007  -146.105    0.000     0.019       -51.596   \n",
       "9  sigma_dec    -0.796  0.006  -124.402    0.000     0.021       -38.583   \n",
       "\n",
       "   Rob p-value  \n",
       "0        0.000  \n",
       "1        0.000  \n",
       "2        0.233  \n",
       "3        0.551  \n",
       "4        0.000  \n",
       "5        0.000  \n",
       "6        0.000  \n",
       "7        0.000  \n",
       "8        0.000  \n",
       "9        0.000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrays = np.column_stack((np.array(list(betas_start.keys())),parameters,se,tratio,p_value,rob_se,rob_tratio,rob_p_value))\n",
    "results = pd.DataFrame(arrays, columns = ['Parameter','Estimate','s.e.','t-ratio0','p-value',\n",
    "                                          'Rob s.e.','Rob t-ratio0','Rob p-value'])\n",
    "\n",
    "results[['Estimate','s.e.','t-ratio0','p-value','Rob s.e.','Rob t-ratio0','Rob p-value']] = (\n",
    "results[['Estimate','s.e.','t-ratio0','p-value','Rob s.e.','Rob t-ratio0','Rob p-value']].apply(pd.to_numeric,errors='coerce'))\n",
    "numeric_cols = results.select_dtypes(include='number').columns\n",
    "results[numeric_cols] = results[numeric_cols].round(3)\n",
    "results # print results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d43ec05",
   "metadata": {},
   "source": [
    "## Goodness-of-fit indices\n",
    "\n",
    "Let's calculate some goodness-of-fit indices now (do not edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66ebbb79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log likelihood at zeros:[-25106.78216908]\n",
      "Initial log likelihood:[-25106.78216908]\n",
      "Final log likelihood:-12828.680069196193\n",
      "rho squared=[0.48903527]\n",
      "adjusted rho squared=[0.48863698]\n",
      "AIC=25677.360138392385\n",
      "BIC=25758.100455329455\n"
     ]
    }
   ],
   "source": [
    "# First let's calculate the GoF indices\n",
    "\n",
    "rho_squared = 1 - ((-result.fun)/(-SLL(np.zeros(len(betas_start)))))\n",
    "adj_rho_squared = 1 - (((-result.fun)-len(betas_start))/(-SLL(np.zeros(len(betas_start)))))\n",
    "\n",
    "AIC = 2*len(betas_start) - 2*(-result.fun)\n",
    "BIC = len(betas_start)*np.log(Nobs) - 2*(-result.fun)\n",
    "\n",
    "LL0t = \"Log likelihood at zeros:\" + str(-SLL(np.zeros(len(betas_start))))\n",
    "LLinit = \"Initial log likelihood:\" + str(-SLL(np.array(list(betas_start.values()))))\n",
    "LLfin = \"Final log likelihood:\" + str(-result.fun)\n",
    "\n",
    "rs1 = \"rho squared=\"+str(rho_squared)\n",
    "rs2 = \"adjusted rho squared=\"+str(adj_rho_squared)\n",
    "ac = \"AIC=\"+str(AIC)\n",
    "bc = \"BIC=\"+str(BIC)\n",
    "\n",
    "# Then let's print the GoF indices\n",
    "\n",
    "print(LL0t)\n",
    "print(LLinit)\n",
    "print(LLfin)\n",
    "\n",
    "print(rs1)\n",
    "print(rs2)\n",
    "print(ac)\n",
    "print(bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671c0bc6",
   "metadata": {},
   "source": [
    "## Save output\n",
    "\n",
    "We can save our output using the code below (do not edit):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0d92097",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{model_name}_results.txt\", 'w') as f:\n",
    "    f.write(f'{LL0t}\\n')\n",
    "    f.write(f'{LLinit}\\n')\n",
    "    f.write(f'{LLfin}\\n')\n",
    "    f.write(f'{rs1}\\n')\n",
    "    f.write(f'{rs2}\\n')\n",
    "    f.write(f'{ac}\\n')\n",
    "    f.write(f'{bc}\\n')\n",
    "    results.to_csv(f, index=False, sep='\\t')\n",
    "results.to_csv(f'{model_name}_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
